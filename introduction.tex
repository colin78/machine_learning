%!TEX root = paper.tex

\section{Introduction}\label{sec:intro}

Logistic regression is a widely-used method for classification.  Given training data $(\M{x}_i, y_i)_{i=1}^n$ with features $\M{x}_i \in \mathbb{R}^p$ and labels $y_i \in \{-1,+1\}$, we would like to find $P(y = 1 | \M{x})$ for an arbitrary vector $\M{x}$.  For logistic regression, we assume a logistic model, where $P(y = 1 | \M{x}) = \dfrac{1}{1 + e^{-y\M{w}^T\M{x}}}$, and $\M{w} \in \mathbb{R}^p$ is a weight vector.  To determine the value of the weight vector, we can do maximum-likelihood estimation, and optimize to find the value of $\M{w}$ which maximizes the negative log-likelihood.  This results in a concave, nonlinear optimization problem solvable via gradient descent.

Alternatively, we might take the Bayesian perspective and assume a prior on $\M{w}$.  This is preferable for cases where we interested in the covariance of the weight vector and/or the predicted probabilities of new data points.   However, this is a difficult problem and there is no simple analytic formula to compute the posterior and predictive distributions directly.  Therefore, in this case we turn to variational methods in order to obtain a close approximation to the posterior for $\M{w}$.  From this, we can then obtain estimates for the predictive distribution $P(y = 1 | \M{x})$.  

In this paper, we develop and test an implementation of Mean-Field Variational Bayes logistic regression based on previous literature.  Paper~\cite{drugowitsch2013variational} provides a walkthrough of MFVB applied to logistic regression, and sample MATLAB code is available on Github.  We develop our own implementation based off of this package of code, and we code these functions in Julia. Going beyond this work, we compare our method against Markov-Chain Monte-Carlo, and implemented this method using an existing package in \texttt{R}.  We performed sensitivity analysis varying the hyperpriors of $\M{w}$ to generate the data, and we obtain a variety of different simulated datasets.  In Section~\ref{sec:comp}, we present train and test set accuracy for all of the simulated datasets, for standard logistic regression, MFVB, and MCMC.  We obtain estimates for the predicted probabilies of MCMC by taking the average of the weight vector $\M{w}$ over all iterations, and then use that to compute the Bernoulli probabilities.  In addition, we also present detailed MCMC results and comparisons to contour plots of the MFVB logistic regression weight posteriors for Dataset 0 in Section~\ref{sec:mcmc}.   

In Section~\ref{sec:mfvb}, we introduce Mean-Field Variational Bayes applied to the problem of logistic regression.  In Section~\ref{sec:implement}, we describe our code implementation of MFVB logistic regression and the simulated datasets we generated to test our methods.  In Section~\ref{sec:mcmc}, we describe the Markov-Chain Monte Carlo method that we used as a benchmark to evaluate the posterior distribution.  In Section~\ref{sec:comp}, we present the out-of-sample accuracy results for all of the methods on the simulated datasets, and in Section~\ref{sec:future}, we describe our goals for future work.  